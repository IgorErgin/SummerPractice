{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dfab34-2bd4-4b6e-9a11-907339ee765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import make_regression_data, mse, log_epoch, RegressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b59a7c-4c15-42cd-b9b3-6a112dea54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: 160\n",
      "Размер валидационного датасета: 40\n",
      "Количество тренировочных батчей: 5\n",
      "Количество валидационных батчей: 2\n",
      "Epoch 10: loss=0.0665, validation_loss=0.0703\n",
      "Epoch 20: loss=0.0369, validation_loss=0.0391\n",
      "Epoch 30: loss=0.0266, validation_loss=0.0278\n",
      "Epoch 40: loss=0.0225, validation_loss=0.0238\n",
      "Epoch 50: loss=0.0205, validation_loss=0.0219\n",
      "Epoch 60: loss=0.0198, validation_loss=0.0208\n",
      "Epoch 70: loss=0.0194, validation_loss=0.0207\n",
      "Early stopping на эпохе 73\n"
     ]
    }
   ],
   "source": [
    "# Модифицируйте существующую линейную регрессию:\n",
    "# - Добавьте L1 и L2 регуляризацию\n",
    "# - Добавьте early stopping\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def l1_l2_regularization(model, l1_lambda, l2_lambda):\n",
    "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "    l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "    return l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Генерируем данные\n",
    "    X, y = make_regression_data(n=200)\n",
    "    \n",
    "    # Создаём датасет и даталоадеры для тренировочных и валидационных данных\n",
    "    dataset = RegressionDataset(X, y)\n",
    "    \n",
    "    # Разделяем данные на тренировочные и валидационные (80/20)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "    \n",
    "    print(f'Размер тренировочного датасета: {len(train_dataset)}')\n",
    "    print(f'Размер валидационного датасета: {len(val_dataset)}')\n",
    "    print(f'Количество тренировочных батчей: {len(train_dataloader)}')\n",
    "    print(f'Количество валидационных батчей: {len(val_dataloader)}')\n",
    "    \n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LinearRegression(in_features=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    # Параметры регуляризации и early stopping\n",
    "    l1_lambda = 0.01\n",
    "    l2_lambda = 0.01\n",
    "    patience = 10\n",
    "    min_delta = 0.001\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Тренировочный цикл\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for i, (batch_X, batch_y) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(batch_X)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            \n",
    "            # Добавляем L1 и L2 регуляризацию\n",
    "            reg_loss = l1_l2_regularization(model, l1_lambda, l2_lambda)\n",
    "            total_loss = loss + reg_loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / (i + 1)\n",
    "        \n",
    "        # Валидационный цикл\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_X, batch_y) in enumerate(val_dataloader):\n",
    "                y_pred = model(batch_X)\n",
    "                loss = criterion(y_pred, batch_y)\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / (i + 1)\n",
    "        \n",
    "        # Логирование\n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_train_loss, validation_loss=avg_val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping на эпохе {epoch}')\n",
    "            break\n",
    "    \n",
    "    # Сохраняем лучшую модель\n",
    "    torch.save(best_model_state, 'linreg_torch.pth')\n",
    "    \n",
    "    # Загружаем лучшую модель\n",
    "    new_model = LinearRegression(in_features=1)\n",
    "    new_model.load_state_dict(torch.load('linreg_torch.pth'))\n",
    "    new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55740a8-d0c4-46eb-82a5-172efd1cf68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: 160\n",
      "Размер валидационного датасета: 40\n",
      "Количество тренировочных батчей: 5\n",
      "Количество валидационных батчей: 2\n",
      "Epoch 10: loss=0.7567, accuracy=0.4750, validation_loss=0.8647, validation_accuracy=0.3594, precision=0.5714, recall=0.3500, f1_score=0.3329, roc_auc=0.8581\n",
      "Epoch 20: loss=0.5963, accuracy=0.6937, validation_loss=0.6378, validation_accuracy=0.9219, precision=0.9591, recall=0.9500, f1_score=0.9502, roc_auc=1.0000\n",
      "Epoch 30: loss=0.5043, accuracy=0.8250, validation_loss=0.5460, validation_accuracy=0.7031, precision=0.9016, recall=0.8250, f1_score=0.8135, roc_auc=1.0000\n",
      "Epoch 40: loss=0.4314, accuracy=0.9625, validation_loss=0.4625, validation_accuracy=0.9844, precision=0.9775, recall=0.9750, f1_score=0.9751, roc_auc=1.0000\n",
      "Epoch 50: loss=0.3884, accuracy=0.9938, validation_loss=0.4146, validation_accuracy=0.9844, precision=0.9775, recall=0.9750, f1_score=0.9751, roc_auc=1.0000\n",
      "Epoch 60: loss=0.3642, accuracy=0.9563, validation_loss=0.3764, validation_accuracy=1.0000, precision=1.0000, recall=1.0000, f1_score=1.0000, roc_auc=1.0000\n",
      "Epoch 70: loss=0.3200, accuracy=1.0000, validation_loss=0.3414, validation_accuracy=1.0000, precision=1.0000, recall=1.0000, f1_score=1.0000, roc_auc=1.0000\n",
      "Epoch 80: loss=0.2967, accuracy=1.0000, validation_loss=0.3264, validation_accuracy=1.0000, precision=1.0000, recall=1.0000, f1_score=1.0000, roc_auc=1.0000\n",
      "Epoch 90: loss=0.2748, accuracy=1.0000, validation_loss=0.3044, validation_accuracy=1.0000, precision=1.0000, recall=1.0000, f1_score=1.0000, roc_auc=1.0000\n",
      "Epoch 100: loss=0.2592, accuracy=1.0000, validation_loss=0.2777, validation_accuracy=1.0000, precision=1.0000, recall=1.0000, f1_score=1.0000, roc_auc=1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def make_regression_data(n=100, noise=0.1, source='random'):\n",
    "    if source == 'random':\n",
    "        X = torch.rand(n, 1)\n",
    "        w, b = 2.0, -1.0\n",
    "        y = w * X + b + noise * torch.randn(n, 1)\n",
    "        return X, y\n",
    "    elif source == 'diabetes':\n",
    "        from sklearn.datasets import load_diabetes\n",
    "        data = load_diabetes()\n",
    "        X = torch.tensor(data['data'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['target'], dtype=torch.float32).unsqueeze(1)\n",
    "        return X, y\n",
    "    else:\n",
    "        raise ValueError('Unknown source')\n",
    "\n",
    "def make_classification_data(n=100, source='random', n_classes=3):\n",
    "    if source == 'random':\n",
    "        # Генерируем сбалансированные данные\n",
    "        X = torch.rand(n, 2)\n",
    "        # Создаём сбалансированные классы\n",
    "        samples_per_class = n // n_classes\n",
    "        y = torch.zeros(n, dtype=torch.long)\n",
    "        X_list = []\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            # Генерируем данные для каждого класса с разными центрами\n",
    "            X_class = torch.rand(samples_per_class, 2) + torch.tensor([i * 2.0, i * 2.0])\n",
    "            X_list.append(X_class)\n",
    "            y[i * samples_per_class:(i + 1) * samples_per_class] = i\n",
    "        \n",
    "        # Добавляем оставшиеся примеры для последнего класса, если n не делится на n_classes\n",
    "        remaining = n - samples_per_class * n_classes\n",
    "        if remaining > 0:\n",
    "            X_class = torch.rand(remaining, 2) + torch.tensor([(n_classes - 1) * 2.0, (n_classes - 1) * 2.0])\n",
    "            X_list.append(X_class)\n",
    "            y[-remaining:] = n_classes - 1\n",
    "        \n",
    "        X = torch.cat(X_list, dim=0)\n",
    "        return X, y\n",
    "    elif source == 'breast_cancer':\n",
    "        from sklearn.datasets import load_breast_cancer\n",
    "        data = load_breast_cancer()\n",
    "        X = torch.tensor(data['data'], dtype=torch.float32)\n",
    "        y = torch.tensor(data['target'], dtype=torch.long)\n",
    "        return X, y\n",
    "    else:\n",
    "        raise ValueError('Unknown source')\n",
    "\n",
    "def mse(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean().item()\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred_classes = torch.argmax(y_pred, dim=1) if y_pred.dim() > 1 else (y_pred > 0.5).float()\n",
    "    return (y_pred_classes == y_true).float().mean().item()\n",
    "\n",
    "def log_epoch(epoch, loss, **metrics):\n",
    "    msg = f\"Epoch {epoch}: loss={loss:.4f}\"\n",
    "    for k, v in metrics.items():\n",
    "        msg += f\", {k}={v:.4f}\"\n",
    "    print(msg)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_pred_proba, num_classes):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    \n",
    "    # Вычисляем precision, recall, F1-score с zero_division=0\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Вычисляем ROC-AUC\n",
    "    try:\n",
    "        if num_classes == 2:\n",
    "            roc_auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        roc_auc = float('nan')\n",
    "    \n",
    "    return precision, recall, f1, roc_auc\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, num_classes, epoch):\n",
    "    # Явно указываем все возможные метки классов\n",
    "    cm = confusion_matrix(y_true.cpu().numpy(), y_pred.cpu().numpy(), labels=range(num_classes))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[f'Class {i}' for i in range(num_classes)],\n",
    "                yticklabels=[f'Class {i}' for i in range(num_classes)])\n",
    "    plt.title(f'Confusion Matrix at Epoch {epoch}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(f'confusion_matrix_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Параметры\n",
    "    num_classes = 3\n",
    "    in_features = 2\n",
    "    \n",
    "    # Генерируем данные\n",
    "    X, y = make_classification_data(n=200, source='random', n_classes=num_classes)\n",
    "    \n",
    "    # Проверяем, что все классы присутствуют\n",
    "    unique_classes = torch.unique(y).numel()\n",
    "    if unique_classes < num_classes:\n",
    "        print(f\"Предупреждение: в данных присутствует только {unique_classes} из {num_classes} классов\")\n",
    "    \n",
    "    # Создаём датасет и разделяем на тренировочный и валидационный\n",
    "    dataset = ClassificationDataset(X, y)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "    \n",
    "    print(f'Размер тренировочного датасета: {len(train_dataset)}')\n",
    "    print(f'Размер валидационного датасета: {len(val_dataset)}')\n",
    "    print(f'Количество тренировочных батчей: {len(train_dataloader)}')\n",
    "    print(f'Количество валидационных батчей: {len(val_dataloader)}')\n",
    "    \n",
    "    # Создаём модель, функцию потерь и оптимизатор\n",
    "    model = LogisticRegression(in_features=in_features, num_classes=num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    # Обучаем модель\n",
    "    epochs = 100\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Тренировочный цикл\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for i, (batch_X, batch_y) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            acc = accuracy(logits, batch_y)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "        \n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        avg_acc = total_acc / (i + 1)\n",
    "        \n",
    "        # Валидационный цикл\n",
    "        model.eval()\n",
    "        val_y_true = []\n",
    "        val_y_pred = []\n",
    "        val_y_pred_proba = []\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (batch_X, batch_y) in enumerate(val_dataloader):\n",
    "                logits = model(batch_X)\n",
    "                loss = criterion(logits, batch_y)\n",
    "                y_pred = torch.argmax(logits, dim=1)\n",
    "                y_pred_proba = torch.softmax(logits, dim=1)\n",
    "                \n",
    "                val_y_true.append(batch_y)\n",
    "                val_y_pred.append(y_pred)\n",
    "                val_y_pred_proba.append(y_pred_proba)\n",
    "                \n",
    "                acc = accuracy(logits, batch_y)\n",
    "                total_val_loss += loss.item()\n",
    "                total_val_acc += acc\n",
    "        \n",
    "        avg_val_loss = total_val_loss / (i + 1)\n",
    "        avg_val_acc = total_val_acc / (i + 1)\n",
    "        \n",
    "        # Объединяем валидационные предсказания\n",
    "        val_y_true = torch.cat(val_y_true)\n",
    "        val_y_pred = torch.cat(val_y_pred)\n",
    "        val_y_pred_proba = torch.cat(val_y_pred_proba)\n",
    "        \n",
    "        # Проверяем, что все классы присутствуют в валидационной выборке\n",
    "        unique_val_classes = torch.unique(val_y_true).numel()\n",
    "        if unique_val_classes < num_classes:\n",
    "            print(f\"Предупреждение на эпохе {epoch}: в валидационной выборке только {unique_val_classes} из {num_classes} классов\")\n",
    "        \n",
    "        # Вычисляем метрики\n",
    "        precision, recall, f1, roc_auc = compute_metrics(val_y_true, val_y_pred, val_y_pred_proba, num_classes)\n",
    "        \n",
    "        # Логирование\n",
    "        if epoch % 10 == 0:\n",
    "            log_epoch(epoch, avg_loss, accuracy=avg_acc, validation_loss=avg_val_loss, \n",
    "                      validation_accuracy=avg_val_acc, precision=precision, recall=recall, \n",
    "                      f1_score=f1, roc_auc=roc_auc)\n",
    "            \n",
    "            # Визуализация confusion matrix\n",
    "            plot_confusion_matrix(val_y_true, val_y_pred, num_classes, epoch)\n",
    "    \n",
    "    # Сохраняем модель\n",
    "    torch.save(model.state_dict(), 'logreg_torch.pth')\n",
    "    \n",
    "    # Загружаем модель\n",
    "    new_model = LogisticRegression(in_features=in_features, num_classes=num_classes)\n",
    "    new_model.load_state_dict(torch.load('logreg_torch.pth'))\n",
    "    new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa855fd-4c6a-482c-b2a3-7fe81f8aa4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
