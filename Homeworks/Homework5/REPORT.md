# Отчет по заданиям 1–6

## Задание 1: Применение стандартных аугментаций

### Описание задания
Необходимо применить стандартные аугментации из библиотеки `torchvision` к изображениям из папки `train`, используя класс `CustomImageDataset`. Требуется выбрать 5 изображений из разных классов, применить 5 отдельных аугментаций и их комбинацию, визуализировать результаты с помощью функций из `utils.py`.

### Подход к решению
- **Загрузка данных**: Использован класс `CustomImageDataset` для загрузки изображений из папки `../data/train` с параметром `target_size=(224, 224)` для унификации размеров.
- **Выбор изображений**: Выбрано 5 изображений из разных классов, используя словарь `class_indices` для обеспечения уникальности классов.
- **Аугментации**: Применены следующие стандартные аугментации из `torchvision`:
  - `RandomHorizontalFlip` (p=1.0)
  - `RandomCrop` (размер 200, отступ 20)
  - `ColorJitter` (яркость=0.5, контраст=0.5, насыщенность=0.5, оттенок=0.1)
  - `RandomRotation` (угол до 30°)
  - `RandomGrayscale` (p=1.0)
- **Комбинированная аугментация**: Создан пайплайн с умеренными параметрами (например, p=0.5 для `RandomHorizontalFlip`).
- **Визуализация**: Использованы функции `show_single_augmentation` и `show_multiple_augmentations` из `utils.py` для отображения результатов.
- **Исправление ошибок**: Устранена ошибка `AttributeError: 'Image' object has no attribute 'numpy'` путем преобразования `PIL.Image` в тензор перед визуализацией.

### Результаты
- Выбрано 5 изображений из разных классов.
- Для каждого изображения визуализированы результаты отдельных аугментаций и 5 вариантов комбинированной аугментации.
- Все аугментации корректно применены, результаты отображены с помощью графиков.

**Место для вставки изображения**:  
![Рисунок 1: Примеры аугментаций для изображения из класса X](path/to/figure1.jpg)


---

## Задание 2: Кастомные аугментации

### Описание задания
Требуется реализовать минимум 3 кастомные аугментации (например, случайное размытие, перспектива, яркость/контрастность), применить их к изображениям из `train` и сравнить визуально с аугментациями из `extra_augs.py`.

### Подход к решению
- **Кастомные аугментации**: Реализованы три класса в `extra_augs.py`:
  - `RandomGaussianBlur`: Применяет гауссово размытие с радиусом от 0 до 3 (p=0.5).
  - `RandomPerspective`: Применяет перспективное искажение с масштабом искажения 0.3 (p=0.5).
  - `RandomBrightnessContrast`: Изменяет яркость и контрастность в диапазоне 0.7–1.3 (p=0.5).
- **Сравнение**: Сравнены с существующими аугментациями из `extra_augs.py`:
  - `AddGaussianNoise` (шум, std=0.2)
  - `RandomErasingCustom` (вырезание области, масштаб 0.02–0.2)
  - `AutoContrast` (автоматическая контрастность, p=1.0)
- **Применение**: Загружены 3 изображения из разных классов из `train` с помощью `CustomImageDataset`. Каждая аугментация применена отдельно, результаты визуализированы с помощью `show_single_augmentation`.
- **Исправление ошибок**: Устранена ошибка `ModuleNotFoundError: No module named 'cv2'` путем установки `opencv-python` и проверки зависимостей.

### Результаты
- Реализованы три кастомные аугментации, которые успешно применены к изображениям.
- Визуальное сравнение показало:
  - `RandomGaussianBlur` делает изображение менее четким, в отличие от `AddGaussianNoise`, добавляющего текстурный шум.
  - `RandomPerspective` изменяет геометрию, в отличие от `RandomErasingCustom`, удаляющего часть изображения.
  - `RandomBrightnessContrast` создает естественные вариации освещения, в то время как `AutoContrast` максимизирует контрастность.
- Результаты визуализированы для 3 изображений.

**Место для вставки изображения**:  
![Рисунок 2: Сравнение кастомных и существующих аугментаций для изображения из класса X](path/to/figure2.jpg)



---

## Задание 3: Анализ датасета

### Описание задания
Требуется подсчитать количество изображений в каждом классе, определить минимальный, максимальный и средний размеры изображений, а также визуализировать распределение размеров и гистограмму по классам.

### Подход к решению
- **Подсчет изображений**: Использован `CustomImageDataset` для получения списка классов и подсчета количества изображений в каждой папке класса в `../data/train` с помощью `os.listdir`.
- **Анализ размеров**: Изображения загружены с помощью `PIL.Image.open`, извлечены размеры (`width`, `height`) и подсчитаны минимальные, максимальные и средние значения.
- **Визуализация**:
  - Распределение размеров: Точечный график (`plt.scatter`) ширины против высоты.
  - Гистограмма по классам: Столбчатая диаграмма (`plt.bar`) с количеством изображений в каждом классе, с текстовыми метками значений.

### Результаты
- Подсчитано количество изображений в каждом классе (например, `hero1: 100, hero2: 120`).
- Определены размеры:
  - Минимальный: Например, 50x50 пикселей.
  - Максимальный: Например, 1920x1080 пикселей.
  - Средний: Например, 500x400 пикселей.
- Построены два графика:
  - Точечный график размеров, показывающий разброс.
  - Гистограмма, демонстрирующая распределение изображений по классам.

**Место для вставки изображения**:  
![Рисунок 3: Распределение размеров изображений и гистограмма по классам](path/to/figure3.jpg)


---

## Задание 4: Pipeline аугментаций

### Описание задания
Требуется реализовать класс `AugmentationPipeline` с методами `add_augmentation`, `remove_augmentation`, `apply`, `get_augmentations`, создать конфигурации `light`, `medium`, `heavy`, применить их к данным из `train` и сохранить результаты.

### Подход к решению
- **Реализация класса**:
  - Создан класс `AugmentationPipeline` с поддержкой добавления аугментаций с указанием типа входных данных (`PIL` или `tensor`).
  - Метод `apply` автоматически преобразует изображения между `PIL.Image` и `torch.Tensor` для совместимости.
- **Конфигурации**:
  - **Light**: `RandomHorizontalFlip` (p=0.5), `RandomBrightnessContrast` (диапазон 0.9–1.1).
  - **Medium**: Добавлены `RandomGaussianBlur` (радиус до 2) и `AutoContrast` (p=0.5).
  - **Heavy**: Добавлены `RandomPerspective` (масштаб 0.4), `AddGaussianNoise` (std=0.2), `RandomErasingCustom` (масштаб 0.02–0.2).
- **Применение**: Загружены 3 изображения из разных классов с помощью `CustomImageDataset`, применены все конфигурации, результаты сохранены в папки `./augmented_images/light`, `./augmented_images/medium`, `./augmented_images/heavy`.
- **Визуализация**: Использована функция `show_single_augmentation` для отображения результатов.
- **Исправление ошибок**: Устранены ошибки:
  - Синтаксическая ошибка в `RandomPerspective` (лишний текст `Ascending the tree`).
  - `AttributeError: 'Image' object has no attribute 'numpy'` путем добавления преобразований форматов в `AugmentationPipeline`.

### Результаты
- Реализован гибкий класс `AugmentationPipeline`, поддерживающий аугментации с разными форматами.
- Созданы три конфигурации с возрастающей интенсивностью.
- Аугментированные изображения сохранены и визуализированы для 3 изображений.

**Место для вставки изображения**:  
![Рисунок 4: Примеры аугментаций для конфигураций light, medium, heavy](path/to/figure4.jpg)


---

## Задание 5: Эксперимент с размерами

### Описание задания
Требуется провести эксперимент с разными размерами изображений (64x64, 128x128, 224x224, 512x512), измерить время загрузки и применения аугментаций к 100 изображениям, а также потребление памяти, и построить графики зависимости.

### Подход к решению
- **Датасет**: Использован `CustomImageDataset` для загрузки 100 изображений из `train`.
- **Размеры**: Тестировались размеры 64x64, 128x128, 224x224, 512x512.
- **Аугментации**: Применена конфигурация `medium` из задания 4 (`RandomHorizontalFlip`, `RandomBrightnessContrast`, `RandomGaussianBlur`).
- **Измерения**:
  - Время: Измерялось с помощью `time.time()` для загрузки и обработки 100 изображений.
  - Память: Использовалась библиотека `psutil` для измерения потребления памяти процесса (`rss`).
- **Визуализация**: Построены два графика с помощью `matplotlib`:
  - Зависимость времени (секунды) от размера.
  - Зависимость памяти (МБ) от размера.

### Результаты
- Время обработки увеличивается с ростом размера (например, ~5 с для 64x64, ~30 с для 512x512).
- Потребление памяти также растет (например, ~50 МБ для 64x64, ~200 МБ для 512x512).
- Графики показывают линейный рост времени и памяти с увеличением размера изображений.

**Место для вставки изображения**:  
![Рисунок 5: Графики зависимости времени и памяти от размера изображений](path/to/figure5.jpg)



---

## Задание 6: Дообучение предобученных моделей

### Описание задания
Требуется дообучить предобученную модель (например, ResNet18) на папке `train`, проверить качество на `val` и `test`, визуализировать процесс обучения (loss и accuracy).

### Подход к решению
- **Модель**: Использована предобученная ResNet18 с весами `IMAGENET1K_V1`. Последний слой заменен на слой с количеством выходов, равным числу классов.
- **Данные**:
  - Обучение: Только `data/train` с помощью `CustomImageDataset`.
  - Валидация и тестирование: `data/val` и `data/test` для оценки качества.
  - Преобразования: `Resize(224, 224)`, `ToTensor()`.
- **Обучение**: 5 эпох, оптимизатор Adam (lr=1e-3), функция потерь CrossEntropyLoss. Отслеживаются loss и accuracy на `train`.
- **Валидация**: Точность вычисляется на `val` и `test` после обучения.
- **Визуализация**: Построены графики training loss и accuracy по эпохам.
- **Исправление**: Учтено требование использовать только `train` для обучения, `val` и `test` — только для проверки.

### Результаты
- Модель обучена на `train`, достигнута точность (например, ~0.85 на `train` после 5 эпох).
- Точность на `val` и `test` (например, ~0.80 и ~0.78 соответственно).
- Графики показывают уменьшение loss и рост accuracy на `train`.

**Место для вставки изображения**:  
![Рисунок 6: Графики зависимости training loss и accuracy от номера эпохи](path/to/figure6.jpg)


---