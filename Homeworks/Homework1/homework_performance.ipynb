{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f664ae-570c-47d0-b84e-f3df130f21b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293adc8c-13b2-4e09-9842-6cfb6d5837fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 Подготовка данных\n",
    "# Создайте большие матрицы размеров:\n",
    "# - 64 x 1024 x 1024\n",
    "# - 128 x 512 x 512\n",
    "# - 256 x 256 x 256\n",
    "# Заполните их случайными числами\n",
    "# Создание матриц\n",
    "matrices = {\n",
    "    \"64x1024x1024\": torch.rand(64, 1024, 1024, device=\"cpu\"),\n",
    "    \"128x512x512\": torch.rand(128, 512, 512, device=\"cpu\"),\n",
    "    \"256x256x256\": torch.rand(256, 256, 256, device=\"cpu\")\n",
    "}\n",
    "\n",
    "# Копии матриц на GPU, если доступен\n",
    "matrices_gpu = {key: mat.to(device) for key, mat in matrices.items()} if torch.cuda.is_available() else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f4fcda-ce24-4ae0-9ede-f838e0a396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 Функция измерения времени\n",
    "# Создайте функцию для измерения времени выполнения операций\n",
    "# Используйте torch.cuda.Event() для точного измерения на GPU\n",
    "# Используйте time.time() для измерения на CPU\n",
    "def measure_time_cpu(operation, *args):\n",
    "    \"\"\" \n",
    "    Время выполнения на cpu\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    result = operation(*args)\n",
    "    end = time.time()\n",
    "    return (end - start) * 1000  # Время в миллисекундах\n",
    "\n",
    "def measure_time_gpu(operation, *args):\n",
    "    \"\"\" \n",
    "    Время выполнения на gpu\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return float(\"inf\")  # Если GPU недоступен, возвращаем бесконечность\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "    torch.cuda.synchronize()\n",
    "    start_event.record()\n",
    "    result = operation(*args)\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return start_event.elapsed_time(end_event)  # Время в миллисекундах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40db2efd-07da-4c87-9233-4e18a43612d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты сравнения операций:\n",
      "     Матрица               Операция  CPU (мс) GPU (мс) Ускорение\n",
      "64x1024x1024    Матричное умножение   608.744      N/A       N/A\n",
      "64x1024x1024  Поэлементное сложение    39.097      N/A       N/A\n",
      "64x1024x1024 Поэлементное умножение    38.000      N/A       N/A\n",
      "64x1024x1024       Транспонирование     1.979      N/A       N/A\n",
      "64x1024x1024   Сумма всех элементов     9.219      N/A       N/A\n",
      " 128x512x512    Матричное умножение   121.682      N/A       N/A\n",
      " 128x512x512  Поэлементное сложение    22.281      N/A       N/A\n",
      " 128x512x512 Поэлементное умножение    18.720      N/A       N/A\n",
      " 128x512x512       Транспонирование     0.030      N/A       N/A\n",
      " 128x512x512   Сумма всех элементов     4.791      N/A       N/A\n",
      " 256x256x256    Матричное умножение    27.262      N/A       N/A\n",
      " 256x256x256  Поэлементное сложение    10.053      N/A       N/A\n",
      " 256x256x256 Поэлементное умножение     9.450      N/A       N/A\n",
      " 256x256x256       Транспонирование     0.044      N/A       N/A\n",
      " 256x256x256   Сумма всех элементов     2.434      N/A       N/A\n"
     ]
    }
   ],
   "source": [
    "#3.3 Сравнение операций\n",
    "# Сравните время выполнения следующих операций на CPU и CUDA:\n",
    "# - Матричное умножение (torch.matmul)\n",
    "# - Поэлементное сложение\n",
    "# - Поэлементное умножение\n",
    "# - Транспонирование\n",
    "# - Вычисление суммы всех элементов\n",
    "\n",
    "# Для каждой операции:\n",
    "# 1. Измерьте время на CPU\n",
    "# 2. Измерьте время на GPU (если доступен)\n",
    "# 3. Вычислите ускорение (speedup)\n",
    "# 4. Выведите результаты в табличном виде\n",
    "# Операции для тестирования\n",
    "operations = {\n",
    "    \"Матричное умножение\": lambda x: torch.matmul(x, x),\n",
    "    \"Поэлементное сложение\": lambda x: x + x,\n",
    "    \"Поэлементное умножение\": lambda x: x * x,\n",
    "    \"Транспонирование\": lambda x: x.transpose(0, 1),\n",
    "    \"Сумма всех элементов\": lambda x: x.sum()\n",
    "}\n",
    "\n",
    "# Сбор результатов\n",
    "results = []\n",
    "\n",
    "for mat_name, mat_cpu in matrices.items():\n",
    "    mat_gpu = matrices_gpu.get(mat_name, None)\n",
    "    for op_name, op in operations.items():\n",
    "        # Измерение времени на CPU\n",
    "        time_cpu = measure_time_cpu(op, mat_cpu)\n",
    "        \n",
    "        # Измерение времени на GPU\n",
    "        time_gpu = measure_time_gpu(op, mat_gpu) if mat_gpu is not None else float(\"inf\")\n",
    "        \n",
    "        # Вычисление ускорения\n",
    "        speedup = time_cpu / time_gpu if time_gpu != 0 and time_gpu != float(\"inf\") else \"N/A\"\n",
    "        \n",
    "        results.append({\n",
    "            \"Матрица\": mat_name,\n",
    "            \"Операция\": op_name,\n",
    "            \"CPU (мс)\": round(time_cpu, 3),\n",
    "            \"GPU (мс)\": round(time_gpu, 3) if time_gpu != float(\"inf\") else \"N/A\",\n",
    "            \"Ускорение\": f\"{round(speedup, 2)}x\" if isinstance(speedup, float) else speedup\n",
    "        })\n",
    "\n",
    "# Вывод результатов в таблице\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nРезультаты сравнения операций:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad7cae-7a78-4287-b1f0-302a95228d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4 Анализ результата\n",
    "\"\"\"\n",
    " Проанализируйте результаты:\n",
    " - Какие операции получают наибольшее ускорение на GPU?\n",
    "Матричное умножение: Эта операция обычно получает наибольшее ускорение на GPU, так как она вычислительно интенсивна и хорошо параллелизуется.\n",
    "Поэлементное сложение и умножение: Эти операции также получают значительное ускорение, так как они легко распараллеливаются на GPU.\n",
    "Транспонирование: Ускорение умеренное, так как транспонирование требует интенсивного доступа к памяти, что может быть узким местом на GPU.\n",
    "Сумма всех элементов: Ускорение зависит от размера матрицы. Для больших матриц оно может быть значительным, но операция редукции менее эффективна на GPU, чем матричные операции.\n",
    " - Почему некоторые операции могут быть медленнее на GPU?\n",
    " Низкая вычислительная интенсивность: Операции, такие как транспонирование или сумма, требуют меньше вычислений и больше операций с памятью, что снижает эффективность GPU, так как они оптимизированы для вычислительно интенсивных задач.\n",
    " Передача данных: Копирование данных между CPU и GPU может занимать значительное время, особенно для небольших матриц. Если операция сама по себе быстрая (например, транспонирование), накладные расходы на передачу данных могут превысить выгоду от выполнения на GPU.\n",
    " - Как размер матриц влияет на ускорение?\n",
    " Большие матрицы (например, 64x1024x1024): Ускорение на GPU обычно выше, так как большие объемы данных позволяют лучше использовать параллелизм GPU. Вычислительные операции (например, матричное умножение) выигрывают больше, чем операции с памятью.\n",
    " Меньшие матрицы (например, 256x256x256): Ускорение может быть ниже из-за меньшего объема данных, что не позволяет полностью загрузить все ядра GPU. Накладные расходы на передачу данных и запуск ядер становятся более заметными.\n",
    " - Что происходит при передаче данных между CPU и GPU?\n",
    " Копирование данных: Передача данных между CPU и GPU (например, tensor.to(device)) требует времени, так как данные копируются через шину PCIe. Это может составлять значительную часть общего времени, особенно для небольших матриц или простых операций.\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
